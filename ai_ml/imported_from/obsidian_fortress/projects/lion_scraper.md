---
id: '20250511112837'
title: Lion Scraper
category: ''
style: ScorpyunStyle
path: ''
created: '2025-05-11'
updated: '2025-05-11'
status: in_progress
priority: normal
summary: ''
longform_summary: ''
tags: []
cssclasses:
- tyrian-purple
- sacred-tech
synapses: []
key_themes: []
bias_analysis: ''
grok_ctx_reflection: ''
quotes: []
adinkra: []
linked_notes: []
---
---
id: "20250520175500"
title: lion_scraper
category: scripts
style: ScorpyunStyle
path: scripts/lion_scraper.md
created: 2025-05-20T17:55:00
updated: 2025-05-20T17:55:00
status: active
priority: high
summary: Annotated scroll for `lion_scraper.py`, the sentinel script powering Africana media curation in the Anacostia Vault.
longform_summary: This scroll documents the logic and sacred function of `lion_scraper.py` â€” a Sunday-deployed news extraction tool that pulls curated headlines for cultural resistance and Afroalgorithmic archiving. It logs selectors, filters content, and triggers CSV ritual exports.
tags:
  - lion_scraper
  - sunday_scraping
  - afroalgorithmic_resistance
  - dom_traversal
  - sacred_automation
cssclasses:
  - tyrian-purple
  - sacred-tech
linked_notes:
  - 01_africana_frontlines
  - technofeudalism_annotations
  - dom_query_patterns
  - structure-note-sunday-curation
  - lion_scraper_output.csv
  - lion_scraper_log.txt
---

## ğŸ¦ `lion_scraper.py` (v4.3.2 â€“ Bulletproof Edition)

`lion_scraper.py` is the **weekly sentinel** of the Anacostia Vaultâ€™s narrative defense grid.  
Built to scrape curated Black, progressive, and AI-focused media sources, it outputs **clean, CSV-formatted headlines**, while logging rejections, anomalies, and selector health for post-scrape audits.

**Version 4.3.2** introduces:

- ğŸ›¡ï¸ **Bulletproof config loading** with fail-safe exits
    
- ğŸ” **Improved diagnostic logging** for article rejection patterns
    
- ğŸ“¦ **CSV + TXT + Debug triplet** for ritual record-keeping
    
- ğŸ§ª _DOM selector analysis now pending via companion scroll:_ `[[dom_query_patterns.md]]`
    

---

## ğŸ§ª Schedule Directive: DOM Pattern Companion

> A companion scroll `[[dom_query_patterns.md]]` is now scheduled.  
> It will house walkthroughs for article selectors, DOM traversal theory, and known parser traps across `lion` sources. This supports better filter tuning and resilient scraping.

---

## ğŸ› ï¸ Core Logic Highlights

- Uses **aiohttp** and **asyncio** for concurrent fetches.
- Loads source selectors from `config_patched.json`.
- Applies **DOM selectors** via `BeautifulSoup` (`soup.select()`).
- Filters noisy or generic content (`"menu"`, `"navigation"`, short titles).
- Outputs:
  - âœ… Valid articles â†’ `output_csv`
  - âš ï¸ Rejected (logged with reasons) â†’ `rejected_titles.csv`
  - ğŸªµ Operational log â†’ `log_txt`

---

## ğŸ” Sunday Scraping Flow

1. **Start session** â†’ Async fetch initiated across all source URLs.
2. **DOM Traversal** â†’ Each site uses its configured CSS selector to locate article blocks.
3. **Title Extraction** â†’ Pulls text via `.get_text(strip=True)` and resolves URLs.
4. **Filtering** â†’ Deduplicates and excludes weak entries.
5. **Output** â†’ Writes `output_csv` for vault import and logs all operations.

---

## ğŸ” Targeted Variables

- `source["article_selector"]`  
  â†’ CSS selector string passed to `soup.select()`, e.g. `div.headline > a`
  
- `seen = set()`  
  â†’ Ensures deduplication across headlines

- `if href.startswith("http")`  
  â†’ Handles relative URL reconstruction

---

## ğŸªµ Ritual Logging

Every scrape logs:

- Valid article count per source âœ…  
- Failures by source âŒ  
- Empty selectors âš ï¸  
- Filtered (low quality) entries â†’ rejected_titles.csv

---

## ğŸ§¬ Upcoming Enhancements

| Feature                  | Status      |
|--------------------------|-------------|
| `--sunday` mode toggle   | ğŸŸ¡ Planned   |
| Metadata injection YAML  | ğŸŸ¢ Active    |
| Selector validation suite| ğŸŸ  In Draft  |
| DOM walkthrough scroll   | âœ… Queued (`dom_query_patterns.md`) |

---

## ğŸœƒ Connected Glyphs

<%*
if (!tp.frontmatter || !Array.isArray(tp.frontmatter.linked_notes)) {
  tR += "âš ï¸ No linked_notes found in frontmatter.";
} else {
  for (let note of tp.frontmatter.linked_notes) {
    tR += `- [[${note.replace(/\.md$/, "")}]]
`;
  }
}
%>
